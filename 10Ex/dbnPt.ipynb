{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26421880/26421880 [00:18<00:00, 1392236.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29515/29515 [00:00<00:00, 72282.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4422102/4422102 [00:02<00:00, 1942042.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5148/5148 [00:00<00:00, 12723793.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "trainset = torchvision.datasets.FashionMNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "testset = torchvision.datasets.FashionMNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=64,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "testloader = DataLoader(testset, batch_size=64,\n",
    "                                         shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBM():\n",
    "    def __init__(self, nv, nh):\n",
    "        self.W = torch.randn(nh, nv)\n",
    "        self.a = torch.randn(1, nh)\n",
    "        self.b = torch.randn(1, nv)\n",
    "        \n",
    "    def sample_h(self, x):\n",
    "        wx = torch.mm(x, self.W.t())\n",
    "        activation = wx + self.a.expand_as(wx)\n",
    "        p_h_given_v = torch.sigmoid(activation)\n",
    "        return p_h_given_v, torch.bernoulli(p_h_given_v)\n",
    "    \n",
    "    def sample_v(self, y):\n",
    "        wy = torch.mm(y, self.W)\n",
    "        activation = wy + self.b.expand_as(wy)\n",
    "        p_v_given_h = torch.sigmoid(activation)\n",
    "        return p_v_given_h, torch.bernoulli(p_v_given_h)\n",
    "    \n",
    "    def train(self, v0, vk, ph0, phk):\n",
    "        self.W += (torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)).t()\n",
    "        self.b += torch.sum((v0-vk), 0)\n",
    "        self.a += torch.sum((ph0-phk), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DBN(nn.Module):\n",
    "    def __init__(self, num_visible, num_hidden1, num_hidden2, num_classes):\n",
    "        super(DBN, self).__init__()\n",
    "        self.fc1 = RBM(num_visible, num_hidden1)\n",
    "        self.fc2 = RBM(num_hidden1, num_hidden2)\n",
    "        self.fc3 = RBM(num_hidden2, num_classes)\n",
    "        self.activation = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        _,x = self.fc1.sample_h(x)\n",
    "        _,x = self.fc1.sample_v(x)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_visible = 784\n",
    "num_hidden1 = 500\n",
    "num_hidden2 = 250\n",
    "num_classes = 10\n",
    "\n",
    "dbn = DBN(num_visible, num_hidden1, num_hidden2, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(dbn.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 1.248\n",
      "[1,   200] loss: 0.662\n",
      "[1,   300] loss: 0.548\n",
      "[1,   400] loss: 0.522\n",
      "[1,   500] loss: 0.485\n",
      "[1,   600] loss: 0.463\n",
      "[1,   700] loss: 0.441\n",
      "[1,   800] loss: 0.434\n",
      "[1,   900] loss: 0.433\n",
      "[2,   100] loss: 0.393\n",
      "[2,   200] loss: 0.405\n",
      "[2,   300] loss: 0.373\n",
      "[2,   400] loss: 0.393\n",
      "[2,   500] loss: 0.385\n",
      "[2,   600] loss: 0.386\n",
      "[2,   700] loss: 0.386\n",
      "[2,   800] loss: 0.360\n",
      "[2,   900] loss: 0.373\n",
      "[3,   100] loss: 0.355\n",
      "[3,   200] loss: 0.328\n",
      "[3,   300] loss: 0.349\n",
      "[3,   400] loss: 0.349\n",
      "[3,   500] loss: 0.348\n",
      "[3,   600] loss: 0.339\n",
      "[3,   700] loss: 0.352\n",
      "[3,   800] loss: 0.338\n",
      "[3,   900] loss: 0.320\n",
      "[4,   100] loss: 0.329\n",
      "[4,   200] loss: 0.322\n",
      "[4,   300] loss: 0.306\n",
      "[4,   400] loss: 0.328\n",
      "[4,   500] loss: 0.315\n",
      "[4,   600] loss: 0.293\n",
      "[4,   700] loss: 0.320\n",
      "[4,   800] loss: 0.309\n",
      "[4,   900] loss: 0.315\n",
      "[5,   100] loss: 0.274\n",
      "[5,   200] loss: 0.298\n",
      "[5,   300] loss: 0.286\n",
      "[5,   400] loss: 0.301\n",
      "[5,   500] loss: 0.300\n",
      "[5,   600] loss: 0.294\n",
      "[5,   700] loss: 0.296\n",
      "[5,   800] loss: 0.294\n",
      "[5,   900] loss: 0.280\n",
      "[6,   100] loss: 0.268\n",
      "[6,   200] loss: 0.281\n",
      "[6,   300] loss: 0.278\n",
      "[6,   400] loss: 0.280\n",
      "[6,   500] loss: 0.280\n",
      "[6,   600] loss: 0.284\n",
      "[6,   700] loss: 0.271\n",
      "[6,   800] loss: 0.267\n",
      "[6,   900] loss: 0.273\n",
      "[7,   100] loss: 0.252\n",
      "[7,   200] loss: 0.253\n",
      "[7,   300] loss: 0.253\n",
      "[7,   400] loss: 0.269\n",
      "[7,   500] loss: 0.265\n",
      "[7,   600] loss: 0.254\n",
      "[7,   700] loss: 0.271\n",
      "[7,   800] loss: 0.265\n",
      "[7,   900] loss: 0.259\n",
      "[8,   100] loss: 0.259\n",
      "[8,   200] loss: 0.229\n",
      "[8,   300] loss: 0.249\n",
      "[8,   400] loss: 0.241\n",
      "[8,   500] loss: 0.259\n",
      "[8,   600] loss: 0.223\n",
      "[8,   700] loss: 0.250\n",
      "[8,   800] loss: 0.260\n",
      "[8,   900] loss: 0.243\n",
      "[9,   100] loss: 0.220\n",
      "[9,   200] loss: 0.213\n",
      "[9,   300] loss: 0.230\n",
      "[9,   400] loss: 0.234\n",
      "[9,   500] loss: 0.245\n",
      "[9,   600] loss: 0.232\n",
      "[9,   700] loss: 0.242\n",
      "[9,   800] loss: 0.222\n",
      "[9,   900] loss: 0.250\n",
      "[10,   100] loss: 0.209\n",
      "[10,   200] loss: 0.232\n",
      "[10,   300] loss: 0.209\n",
      "[10,   400] loss: 0.211\n",
      "[10,   500] loss: 0.236\n",
      "[10,   600] loss: 0.227\n",
      "[10,   700] loss: 0.217\n",
      "[10,   800] loss: 0.221\n",
      "[10,   900] loss: 0.231\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = Variable(inputs.view(-1, num_visible)), Variable(labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = dbn(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the DBN classifier on the 10000 test images: 88 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    images, labels = Variable(images.view(-1, num_visible)), Variable(labels)\n",
    "    outputs = dbn(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the DBN classifier on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
